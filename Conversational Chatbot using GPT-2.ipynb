{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5d62cace",
   "metadata": {},
   "source": [
    "### Introduction:\n",
    "The project aims to develop a conversational chatbot using the GPT-2 language model. GPT-2 is a state-of-the-art transformer-based model capable of generating human-like text based on input prompts. The chatbot will engage users in natural language dialogues, providing responses that mimic human conversation."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "62e24200",
   "metadata": {},
   "source": [
    "### Problem Statement:\n",
    "The objective is to create a chatbot that can understand user input, generate contextually relevant responses, and sustain meaningful conversations on a variety of topics. The chatbot should be user-friendly, responsive, and capable of handling both casual and formal interactions."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "404f3e08",
   "metadata": {},
   "source": [
    "### Implementation:\n",
    "The project will be implemented using Python and the Hugging Face Transformers library, which provides easy-to-use interfaces for working with transformer-based models like GPT-2."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af61e57f",
   "metadata": {},
   "source": [
    "### Code Overview:\n",
    "The provided code defines a Chatbot class with methods for initializing the GPT-2 model and tokenizer, generating responses, and starting the chat loop.\n",
    "\n",
    "### - Initialization: \n",
    "The __init__ method initializes the chatbot by loading the pre-trained GPT-2 model and tokenizer.\n",
    "\n",
    "### - Response Generation: \n",
    "The generate_response method takes user input, tokenizes it, and feeds it into the GPT-2 model to generate a response.\n",
    "\n",
    "### - Chat Loop: \n",
    "The start_chat method initiates the conversation loop, where the chatbot prompts the user for input, generates a response, and continues the conversation until the user types \"exit\"."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ac52541",
   "metadata": {},
   "source": [
    "### Usage:\n",
    "To interact with the chatbot, users can run the provided Python script. The chatbot will greet the user, prompt for input, and generate responses based on user input. The conversation continues until the user types \"exit\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4d28b1b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\anaconda3\\Lib\\site-packages\\transformers\\utils\\generic.py:260: UserWarning: torch.utils._pytree._register_pytree_node is deprecated. Please use torch.utils._pytree.register_pytree_node instead.\n",
      "  torch.utils._pytree._register_pytree_node(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Chatbot: Hi! I'm here to chat with you. You can type 'exit' to end the conversation.\n",
      "You: What is a Chatbot?\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\anaconda3\\Lib\\site-packages\\transformers\\generation\\configuration_utils.py:362: UserWarning: `do_sample` is set to `False`. However, `temperature` is set to `0.7` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `temperature`.\n",
      "  warnings.warn(\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Chatbot: What is a Chatbot?\n",
      "\n",
      "Chatbots are a new type of chatbot that can be used to communicate with other bots. They are used to communicate with other bots and to communicate with other bots. Chatbots are used to communicate with other\n"
     ]
    }
   ],
   "source": [
    "from transformers import GPT2LMHeadModel, GPT2Tokenizer\n",
    "\n",
    "class Chatbot:\n",
    "    def __init__(self):\n",
    "        self.tokenizer = GPT2Tokenizer.from_pretrained(\"gpt2\")\n",
    "        self.model = GPT2LMHeadModel.from_pretrained(\"gpt2\")\n",
    "\n",
    "    def generate_response(self, input_text, max_length=50, temperature=0.7):\n",
    "        input_ids = self.tokenizer.encode(input_text, return_tensors=\"pt\")\n",
    "        output = self.model.generate(input_ids, max_length=max_length, temperature=temperature)\n",
    "        response = self.tokenizer.decode(output[0], skip_special_tokens=True)\n",
    "        return response\n",
    "\n",
    "    def start_chat(self):\n",
    "        print(\"Chatbot: Hi! I'm here to chat with you. You can type 'exit' to end the conversation.\")\n",
    "        while True:\n",
    "            user_input = input(\"You: \")\n",
    "            if user_input.lower() == \"exit\":\n",
    "                print(\"Chatbot: Goodbye! Take care.\")\n",
    "                break\n",
    "            response = self.generate_response(user_input)\n",
    "            print(\"Chatbot:\", response)\n",
    "\n",
    "# Creation of an instance of the chatbot\n",
    "chatbot = Chatbot()\n",
    "# Function to start the conversation\n",
    "chatbot.start_chat()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c8c0e22f",
   "metadata": {},
   "source": [
    "### Future Enhancements:\n",
    "\n",
    "### - Fine-tuning: \n",
    "Fine-tune the GPT-2 model on specific datasets to improve response quality and relevance.\n",
    "\n",
    "### - Integration: \n",
    "Integrate the chatbot into web or mobile applications to reach a wider audience.\n",
    "\n",
    "### - Personalization: \n",
    "Implement user profiles and context tracking to personalize responses based on user preferences and history.\n",
    "\n",
    "### - Multi-turn Dialogue: \n",
    "Enhance the chatbot to support multi-turn dialogues and maintain context across multiple interactions."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0f3c77a",
   "metadata": {},
   "source": [
    "### Conclusion:\n",
    "The project demonstrates the potential of transformer-based models like GPT-2 in developing conversational AI systems. By leveraging pre-trained models and natural language processing techniques, the chatbot can engage users in meaningful conversations, providing a seamless and interactive user experience."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f931f53",
   "metadata": {},
   "source": [
    "### Acknowledgements:\n",
    "The project utilizes the Hugging Face Transformers library and pre-trained GPT-2 model, which are developed and maintained by the open-source community. Special thanks to the contributors and developers who have made these resources accessible for building conversational AI applications."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
